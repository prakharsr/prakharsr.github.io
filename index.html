<center><h1>Prakhar Sharma</h1></center>
<center><a href="mailto:prakhar03sharma@gmail.com">prakhar03sharma@gmail.com</a> | <a href="tel:9027265188">+91-9027265188</a> | <a href="https://github.com/prakharsr">Github</a> | <a href="https://www.linkedin.com/in/prakhar-sharma-733736175/">LinkedIn</a> | <a href="https://drive.google.com/file/d/1A68yyE7-3-JzRN0KDAVJ5UrZqsNFXzEG/view?usp=sharing">Resume</a></center>
<br>
<p>Dear Recruiter, </p>
<br>
<p>
    I am currently a Software Engineer at Sheru. I completed my B.Tech + M.Tech integrated
    course in Information Technology from IIIT Gwalior. I have a wide range of experience ranging from full stack
    development, hybrid development, blockchain development, familiarity with Linux and
    basic kernel development.
    <br><br>
    I am working with Sheru from June 2021 to present as a Full Stack Engineer. My work experience in that duration is : 

    <ul>
        <b> Kafka - Product Owner </b>

        <li> Responsible for complete end to end implementation and deployment of a confluent kafka node with zookeeper, kafka server, schema-registry, kafka-rest, kafka-connect, ksqldb and control-center in AWS EC2 alongwith SSL and SASL in all of the components. Achieved max production and consumption throughput of 100 MBps while benchmarking
        </li>
        <li> Responsible for deployment of an InfluxDB node on an AWS EC2 server and rearchitecting data storage from earlier storing data in MongoDB and AWS S3 to using Kafka, Telegraf and InfluxDB to store time based IoT device data, microservice metric data and AWS EC2 node metric data
        </li>
        <li> Used MongoDB source and sink connectors and Google Firebase sink connectors to ingest/ egest data
        </li>
        <li> Responsible for creating and implementing solutions which made use of kafka in microservices leading to improved, scalable, reliable and robust architectures and increased message consumption throughput
            <ul>
                <li> Collected metrics from each of the microservices and AWS EC2 instances and produced to kafka, consumed by telegraf and ingested by InfluxDB to generate alerts based on resource consumption and availability of microservices/ instances and to create dashboards in influxdb to monitor performance of APIs in microservices, track resource consumption, analysis layer for further optimizations
                </li>
                <li> Rearchitected the alerts microservice which used to consume change data from mongodb change streams and shifted it to consume from kafka topics, solving problems related to scalability, reliabiility, resuming consumption from where we left off, message consumption acknowledgement, low throughput due to a single consumer. With Kafka we were able to have parallel consumers in a topic using partitions to increase throughput of microservice using worker child processes in node. In order to further optimize and improve throughput, moved individual CRUD operations to a kafka topic which is consumed to do bulk operations in mongo and firebase. These optimizations led to a 1000x increase in consumption throughput and lower costs needed for storage (in kafka partitions), CPU and memory resources
                    </li>
                <li> Rearchitected the asset and telemetry microservice from doing create/ update operations in mongo and firebase to producing to a topic in kafka, solving problem of scalability and led to a huge increase in production throughput and lower costs needed for CPU and memory resources
                    </li>
                <li> In order to solve the problem of scalability with APIs, created a reusable class which utlized kafka by and used parent and child process and nodejs event emitters to increase throughput by parallel consumption, solving problems related to scalability, reliabiility, resuming consumption from where we left off, message consumption acknowledgement
                    </li>
            </ul>
        </li>
        <br><br>

<b >Microservice related tasks </b>

<li> Created and integrated kafka based solutions which made use of kafka in microservices leading to improved, scalable, reliable and robust architectures and increased message consumption throughput
</li>
<li> Rearchitected the orchestration platform to solve the problem of scalability and adaptability to changes in hierarchy of organisation
   </li>
<li> Made parsers for different types of IoTs across different Battery Management Systems, deploying RabbitMQ and using it as message queue
   </li>
<li> Created metrics related to asset telemetry which help suggest the best reliable hardware/ manufacturer suitable for us alongiwth optimizations in internal socket handling in node
</li>
<li> Changed architecture of battery swapping workflow from using agenda.js for dynamic jobs to using this kafka architecture and mongodb transactions to achieve guarantess, finality and robustness
</li>
<li> Responsible for designing and creating the Kilometer Estimation microservice from scratch to completion for predicting kms with accuracy using gps and soc data of a battery utilizing influxdb to get geolocation and battery data and writing APIs in typescript
</li>
<li> Responsible for designing and creating a microservice  for creating cron jobs using agenda.js which is used to automate various workflows and to query health of microservices and generate alerts
</li>
<li> React Dashboard Backend And Frontend - Responsible for designing the architecture of backend of a nodejs react app utilizing appolo graphql, responsible for creation of shell script for remote deployment and designing a build process for compressing the app using brotli, leading to very fast website, responsible for creating web pages to accomplish various tasks using react.js
</li>

<br><br>

<b> Deployments, Shell Scripting and data migrations </b>

<li> Created shell scripts for replication of influxdb data across EC2 servers, automatic weekly updation of OSRM data using scripts for automated EC2 creation/ deletion, automated build and deployment of react apps, created various daemons to solved availability related issues etc.
   </li>
<li> Creation of a fully secure node from a baremetal VM in E2E networks
</li>
<li> Nginx deployment alongwith certbot, load balancing 
</li>
<li> Responsible for creation of scripts for migration of old data stored in AWS S3, validating and modifying it to use new schema, while utilizing kafka and telegraf for parallel ingestion
</li>


    </ul>

    <br>    <br>
    I interned with Sheru from June to September 2020 as a Django Developer. It involved the
    development of an admin dashboard for analyzing the business architecture from the
    perspective of the supply and demand. I was involved in finding ways in which the business
    of a ride sharing application can be boosted, exploring the architecture of real time location
    analyzing module, geospatial analysis of riders and drivers, managing business of supply
    side (drivers), managing business of demand side (riders) and how to make the most out of
    the existing data we have by segmentation methods and then acting upon them by creating
    campaigns, increasing customer reach by making a custom news poster to companyâ€™s
    Facebook Page. I am well versed with Django, Javascript, Python and MongoDB.
    <br>    <br>
    I am also a contributor to open source projects such as Linux Foundation's Accord Project and I've participated in hackathons such as GitCoin's Polkadot hackathon.
    <br>    <br>
    I also have prior experience with Angular development alongwith its integration with Ionic
    Framework to build hybrid applications. For my B.Tech Project, I developed a time series
    prediction tool using fuzzy logic and fuzzy information retrieval system to predict the trends
    in stock markets using Python, using metrics such as RSI, common candlestick patterns,
    NIFTY50/ BSI OHLC data.
    <br>    <br>
    I also have experience with Blockchains, decentralised application development and
    the research in my M.Tech Project explores the integration of IoT and
    Blockchain to propose an architecture which overcomes the existing issues with IoT sector
    involving current problems with device integrity, device registration, security and data privacy using Hyperledger Aries and BeagleBone Black as the IoT device. I also am
    well versed with other Blockchains such as Bitcoin, Ethereum and am very interested in the
    decentralsied finance (De-Fi) sector.
    <br>    <br>
    Some interesting projects that I worked on are - 
    <li>
    	<li><a href="https://github.com/prakharsr/hyperledger-aries-iot"> M.Tech Research Project</a></li>
    	<li><a href="https://github.com/prakharsr/Stock-Market-Trend-Forecasting"> B.Tech Research Project</a></li>
    	<li><a href="https://drive.google.com/file/d/11zscT7r1ZbB4wN9muoBa5R0542izacJ9/view?usp=sharing"> Colloquium Report (Internship Project)</a></li>
    	<li><a href="https://github.com/prakharsr/techdocs"> Accord Project Documentation migration</a></li>
    	<li><a href="https://github.com/prakharsr/polkadothackathon"> Polkadot Hackathon</a></li>
    	<li><a href="https://github.com/prakharsr/USB-device-drivers"> USB device drivers</a></li>
    	<li><a href="https://github.com/prakharsr/CN-Switch-Log-Sniffer"> Switch Log Sniffer</a></li>
    	
    </li>
</p>
<br>
<span>Prakhar Sharma</span>
